{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using RNNs to Label Sequences\n",
    "\n",
    "We use RNN models to label secondary structure annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Imports for data loading and classification\n",
    "#\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, SimpleDeepRNN\n",
    "import keras.preprocessing.sequence\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as ps\n",
    "import sys\n",
    "\n",
    "\n",
    "#\n",
    "# Setup matplotlib and ipython\n",
    "#\n",
    "%matplotlib inline\n",
    "\n",
    "# random seed\n",
    "R_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# The character mapping to encode amino acid sequences.\n",
    "# Non-AA chars should be mapped to X, or 0.\n",
    "#\n",
    "\n",
    "AAs = ['X','I','L','V','F','M','C','A','G','P','T','S','Y','W','Q','N','H','E','D','K','R']\n",
    "AAIndexes = {AAs[i] : i for i in range(len(AAs))}\n",
    "\n",
    "def encodeAA(x) :\n",
    "    # Encode an amino acid sequence\n",
    "    if x not in AAIndexes :\n",
    "        return 0\n",
    "    return AAIndexes[x]\n",
    "\n",
    "def seqToIdxs(seq) :\n",
    "    return map(encodeAA, seq.strip().upper())\n",
    "\n",
    "#\n",
    "#  Functions for loading sequences and background distributions\n",
    "#\n",
    "\n",
    "def loadSeqs(seqs_file, num_lines=sys.maxint) :\n",
    "    seqs = []\n",
    "    with open(seqs_file) as in_f :\n",
    "        for line in in_f :\n",
    "            seqs.append(seqToIdxs(line))\n",
    "            if len(seqs) >= num_lines : break\n",
    "    return seqs\n",
    "\n",
    "def loadFeatureSeqs(task_name, num_lines=sys.maxint) :\n",
    "    path = '/home/gene245/cprobert/seq_features/%s_seqs.txt' % task_name\n",
    "    return loadSeqs(path, num_lines)\n",
    "\n",
    "def loadFeatureBkgrdSeqs(task_name, num_lines=sys.maxint) :\n",
    "    path = '/home/gene245/cprobert/seq_features/%s_featurebackground_seqs.txt' % task_name\n",
    "    return loadSeqs(path, num_lines)\n",
    "\n",
    "def loadGlobalBkgrdSeqs(task_name, num_lines=sys.maxint) :\n",
    "    path = '/home/gene245/cprobert/seq_features/%s_globalbackground_seqs.txt' % task_name\n",
    "    return loadSeqs(path, num_lines)\n",
    "\n",
    "def createBinaryLabelVector(length, label) :\n",
    "    if label == 1 :\n",
    "        return np.ones(length, dtype=int)\n",
    "    return np.zeros(length, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 8, 8, 8, 18, 12, 13, 9, 1, 1]\n",
      "[15, 3, 15, 3, 11, 10, 17, 2, 18, 11]\n",
      "[2, 11, 1, 14, 12, 3, 9, 17, 10, 15]\n",
      "[1 1 1]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Try loading some data\n",
    "print(loadFeatureSeqs('transmembrane-region',1)[0][:10])\n",
    "print(loadFeatureBkgrdSeqs('transmembrane-region',1)[0][:10])\n",
    "print(loadGlobalBkgrdSeqs('transmembrane-region',1)[0][:10])\n",
    "print(createBinaryLabelVector(3,1))\n",
    "print(createBinaryLabelVector(3,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try loading data and converting to keras types\n",
    "\n",
    "seqs = loadFeatureSeqs('transmembrane-region',1)\n",
    "proc_seqs = keras.preprocessing.sequence.pad_sequences(seqs, maxlen=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Declare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getsimpleLSTM(input_dim=len(AAs)+1) :\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Embedding(input_dim, 256))\n",
    "    model.add(LSTM(256, 128, activation='sigmoid', inner_activation='hard_sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, 1, init='uniform'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "def getsimpleRNN(input_dim=len(AAs)+1) :\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Embedding(input_dim, 256))\n",
    "    model.add(SimpleDeepRNN(256, 128, truncate_gradient=5))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, 1, init='uniform'))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Try things out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the raw sequences as lists of ints\n",
    "seqs_pos = loadFeatureSeqs('transmembrane-region',1000)\n",
    "seqs_neg = loadGlobalBkgrdSeqs('transmembrane-region',1000)\n",
    "\n",
    "labels_pos = createBinaryLabelVector(len(seqs_pos), 1)\n",
    "labels_neg = createBinaryLabelVector(len(seqs_neg), 0)\n",
    "\n",
    "seqs = seqs_pos + seqs_neg\n",
    "labels = np.append(labels_pos, labels_neg)\n",
    "\n",
    "seqs = keras.preprocessing.sequence.pad_sequences(seqs, maxlen=100)\n",
    "assert(seqs.shape[0] == labels.shape[0])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(seqs, labels, test_size=0.1, random_state=R_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Declare and compile the model\n",
    "model = getsimpleLSTM()\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "1800/1800 [==============================] - 30s - loss: 0.6943    \n",
      "Epoch 1\n",
      "1800/1800 [==============================] - 31s - loss: 0.6935    \n",
      "Epoch 2\n",
      "1800/1800 [==============================] - 30s - loss: 0.6935    \n",
      "Epoch 3\n",
      "1800/1800 [==============================] - 31s - loss: 0.6941    \n",
      "Epoch 4\n",
      "1800/1800 [==============================] - 31s - loss: 0.6940    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': [0, 1, 2, 3, 4],\n",
       " 'loss': [0.6943276058227037,\n",
       "  0.69346999095307527,\n",
       "  0.693531607820701,\n",
       "  0.69412398574189027,\n",
       "  0.69399324933160988]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=5, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s - loss: 0.6942     \n",
      "0.693791053267\n",
      "(6249114257931851, 9007199254740992)\n",
      "1800/1800 [==============================] - 3s - loss: 0.6938     \n",
      "0.693881899323\n",
      "(6249932526461317, 9007199254740992)\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(X_test, y_test, batch_size=16)\n",
    "print score\n",
    "print score.as_integer_ratio()\n",
    "\n",
    "score = model.evaluate(X_train, y_train, batch_size=16)\n",
    "print score\n",
    "print score.as_integer_ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 123s   \n",
      "Untaring file...\n",
      "(45000, 3, 32, 32)\n",
      "(45000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Try Keras examples\n",
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data(test_split=0.1, seed=113)\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.pkl\n",
      "33218560/33213513 [==============================] - 3s     \n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"imdb.pkl\", nb_words=None, skip_top=0, maxlen=None, test_split=0.1, seed=113)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 10, 2, 257, 7, 25, 18, 69, 4195, 1513, 16, 121, 41, 2, 73, 3, 26, 14, 20, 33, 1758, 303, 4, 16, 75, 121, 14, 299, 15, 6, 153, 8, 112, 263, 18, 14, 20, 22, 96, 22, 16, 101, 219, 14, 21, 4, 12, 13, 9, 11, 12, 13, 9, 11, 61, 257, 7, 10886, 17974, 6, 15138, 13325, 4, 29, 18, 3, 42, 238, 3, 10, 45, 4874, 146, 272, 15138, 17974, 6, 62, 191, 7, 2, 17832, 4, 28, 2, 4570, 281, 206, 15, 2, 40383, 6009, 5, 8198, 98697, 8, 2, 19456, 3, 6, 257, 7, 66280, 8062, 4, 12, 13, 9, 11, 12, 13, 9, 11, 14, 56, 39, 7, 163, 10355, 5908, 3, 2, 407, 357, 1437, 53, 1201, 768, 2, 9732, 4, 12, 13, 9, 11, 12, 13, 9, 11, 19, 81, 196, 31, 275, 218, 40, 19, 3, 561, 1789, 695, 10872, 4, 34, 10, 48, 222, 4, 558, 23, 727, 3982, 4, 34, 20, 15, 41, 149, 1699, 116, 4, 12, 13, 9, 11, 12, 13, 9, 11, 121, 174, 25, 318, 4, 470, 3, 33, 19, 4562, 19, 2, 216, 4, 18, 20, 70, 62, 357, 4, 318, 3, 121, 6, 553, 526, 55, 1573, 16582, 49, 19, 2839, 7, 2, 7106, 4, 19]\n",
      "[0 1]\n",
      "1000 1000\n",
      "216\n",
      "198\n",
      "102063\n"
     ]
    }
   ],
   "source": [
    "print X_train[0]\n",
    "print np.unique(y_train)\n",
    "print len(X_train), len(y_train)\n",
    "X_train = X_train[:1000]\n",
    "y_train = y_train[:1000]\n",
    "print len(X_train[0])\n",
    "print len(X_train[1])\n",
    "print max(map(max, X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "1000/1000 [==============================] - 48s - loss: 0.6948    \n",
      "Epoch 1\n",
      "1000/1000 [==============================] - 50s - loss: 0.6980    \n",
      "Epoch 2\n",
      "1000/1000 [==============================] - 51s - loss: 0.6942    \n",
      "Epoch 3\n",
      "1000/1000 [==============================] - 54s - loss: 0.6940    \n",
      "Epoch 4\n",
      "1000/1000 [==============================] - 54s - loss: 0.6946    \n",
      "Epoch 5\n",
      "1000/1000 [==============================] - 54s - loss: 0.6935    \n",
      "Epoch 6\n",
      "1000/1000 [==============================] - 51s - loss: 0.6955    \n",
      "Epoch 7\n",
      "1000/1000 [==============================] - 55s - loss: 0.6945    \n",
      "Epoch 8\n",
      "1000/1000 [==============================] - 53s - loss: 0.6942    \n",
      "Epoch 9\n",
      "1000/1000 [==============================] - 57s - loss: 0.6928    \n",
      " 672/2500 [=======>......................] - ETA: 8s - loss: 0.6974"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 102094 is out of bounds for size 102094\nApply node that caused the error: AdvancedSubtensor1(<TensorType(float64, matrix)>, Flatten{1}.0)\nInputs shapes: [(102094, 256), (3200,)]\nInputs strides: [(2048, 8), (4,)]\nInputs types: [TensorType(float64, matrix), TensorType(int32, vector)]\nUse the Theano flag 'exception_verbosity=high' for a debugprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c8d4eef306b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/software/python_anaconda/2.2.0/lib/python2.7/site-packages/Keras-0.0.1-py2.7.egg/keras/models.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, X, y, batch_size, show_accuracy, verbose)\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[0mlog_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'acc.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m                 \u001b[0mlog_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[0mtot_score\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/python_anaconda/2.2.0/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m                     \u001b[1;31m# For the CVM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m                     gof.vm.raise_with_op(self.fn.nodes[self.fn.position_of_error],\n\u001b[1;32m--> 588\u001b[1;33m                                          self.fn.thunks[self.fn.position_of_error])\n\u001b[0m\u001b[0;32m    589\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m                     \u001b[1;31m# For the c linker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/python_anaconda/2.2.0/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 102094 is out of bounds for size 102094\nApply node that caused the error: AdvancedSubtensor1(<TensorType(float64, matrix)>, Flatten{1}.0)\nInputs shapes: [(102094, 256), (3200,)]\nInputs strides: [(2048, 8), (4,)]\nInputs types: [TensorType(float64, matrix), TensorType(int32, vector)]\nUse the Theano flag 'exception_verbosity=high' for a debugprint of this apply node."
     ]
    }
   ],
   "source": [
    "max_features = max(max(map(max, X_train)), max(map(max, X_test)))\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=200, dtype='int32')\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=200, dtype='int32')\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_features, 256))\n",
    "# model.add(LSTM(256, 128, activation='sigmoid', inner_activation='hard_sigmoid'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(128, 1))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=16, nb_epoch=10)\n",
    "score = model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
